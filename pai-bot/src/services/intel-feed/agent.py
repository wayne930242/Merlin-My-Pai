#!/usr/bin/env python3
"""Intel Feed Agent - LangGraph å¯¦ç¾

ä½¿ç”¨ LangGraph StateGraph ç®¡ç†æ–°èåˆ†ææµç¨‹ï¼š
score â†’ filter â†’ outline â†’ format â†’ merge
"""

from __future__ import annotations

import json
import os
import sys
from typing import TYPE_CHECKING, Any, Literal, TypedDict

from langchain_core.prompts import ChatPromptTemplate
from langchain_google_genai import ChatGoogleGenerativeAI
from langgraph.graph import END, START, StateGraph
from pydantic import BaseModel, Field

if TYPE_CHECKING:
    from langgraph.graph.state import CompiledStateGraph

# Constants
MIN_RELEVANCE_SCORE = 6
ITEMS_PER_CATEGORY = 3

CATEGORY_META = {
    "ai": {"label": "AI/æŠ€è¡“", "emoji": "ğŸ¤–"},
    "startup": {"label": "å‰µæ¥­/ç”¢å“", "emoji": "ğŸ’¼"},
    "productivity": {"label": "ç”Ÿç”¢åŠ›", "emoji": "ğŸ¯"},
    "trpg": {"label": "TRPG", "emoji": "ğŸ²"},
    "gamedev": {"label": "éŠæˆ²é–‹ç™¼", "emoji": "ğŸ®"},
}


# Type definitions
class FeedItem(TypedDict):
    """åŸå§‹æ–°èé …ç›®"""

    id: str
    source: Literal["reddit", "rss"]
    sourceName: str
    category: str
    title: str
    url: str
    score: int | None
    comments: int | None
    author: str | None
    publishedAt: str | None
    summary: str | None


class ScoredItem(FeedItem):
    """å«è©•åˆ†çš„é …ç›®"""

    relevanceScore: int


class DigestItem(TypedDict):
    """æ‘˜è¦é …ç›®"""

    title: str
    summary: str
    url: str
    source: str


class CategoryDigest(TypedDict):
    """åˆ†é¡æ‘˜è¦"""

    category: str
    label: str
    emoji: str
    items: list[DigestItem]


class IntelFeedState(TypedDict):
    """LangGraph ç‹€æ…‹"""

    # è¼¸å…¥
    items: list[FeedItem]

    # ä¸­é–“ç‹€æ…‹
    scored_items: list[ScoredItem]
    filtered_items: dict[str, list[ScoredItem]]  # category â†’ items
    outlines: dict[str, str]  # category â†’ outline

    # è¼¸å‡º
    digests: list[CategoryDigest]

    # æ§åˆ¶
    categories_to_process: list[str]


# Pydantic models for structured output
class RelevanceScore(BaseModel):
    """ç›¸é—œæ€§è©•åˆ†"""

    score: int = Field(description="1-10 çš„ç›¸é—œæ€§åˆ†æ•¸", ge=1, le=10)


def _check_api_key() -> None:
    """æª¢æŸ¥ API key"""
    if not os.environ.get("GOOGLE_API_KEY") and not os.environ.get("GEMINI_API_KEY"):
        raise ValueError("GOOGLE_API_KEY æˆ– GEMINI_API_KEY ç’°å¢ƒè®Šæ•¸æœªè¨­å®š")


def get_lite_llm() -> ChatGoogleGenerativeAI:
    """å–å¾—è¼•é‡ LLMï¼ˆç”¨æ–¼è©•åˆ†ç­‰ç°¡å–®ä»»å‹™ï¼‰"""
    _check_api_key()
    return ChatGoogleGenerativeAI(
        model="gemini-2.5-flash-lite",
        temperature=0,
    )


def get_main_llm() -> ChatGoogleGenerativeAI:
    """å–å¾—ä¸»è¦ LLMï¼ˆç”¨æ–¼æ‘˜è¦ç”Ÿæˆç­‰è¤‡é›œä»»å‹™ï¼‰"""
    _check_api_key()
    return ChatGoogleGenerativeAI(
        model="gemini-2.5-flash",
        temperature=0,
    )


def create_intel_feed_graph() -> CompiledStateGraph[IntelFeedState]:
    """å»ºç«‹ Intel Feed è™•ç†åœ–"""

    lite_llm = get_lite_llm()
    main_llm = get_main_llm()

    # Score prompt
    score_prompt = ChatPromptTemplate.from_messages(
        [
            (
                "system",
                """ä½ æ˜¯ä¸€å€‹å…§å®¹è©•åˆ†åŠ©æ‰‹ã€‚
è©•ä¼°é€™ç¯‡æ–‡ç« å°ä¸€ä½é—œæ³¨ AI/æŠ€è¡“ã€å‰µæ¥­ã€ç”Ÿç”¢åŠ›å·¥å…·å’Œ TRPG çš„é–‹ç™¼è€…çš„ç›¸é—œæ€§ã€‚

è©•åˆ†æ¨™æº– (1-10):
- 1-3: ä¸ç›¸é—œæˆ–ä½å“è³ªï¼ˆå»£å‘Šã€é‡è¤‡ã€ç„¡å¯¦è³ªå…§å®¹ï¼‰
- 4-5: ä¸€èˆ¬å…§å®¹ï¼Œç„¡ç‰¹æ®Šåƒ¹å€¼
- 6-7: æœ‰è¶£ã€åŸå‰µæˆ–æœ‰åƒ¹å€¼çš„å…§å®¹
- 8-10: é«˜åƒ¹å€¼å…§å®¹ï¼Œå¿…è®€

åªå›ç­”ä¸€å€‹æ•¸å­— (1-10)ï¼Œä¸è¦å…¶ä»–å…§å®¹ã€‚""",
            ),
            (
                "human",
                "æ¨™é¡Œ: {title}\nä¾†æº: {source}\nåˆ†é¡: {category}",
            ),
        ]
    )

    # Outline prompt
    outline_prompt = ChatPromptTemplate.from_messages(
        [
            (
                "system",
                """ä½ æ˜¯ä¸€ä½è³‡æ·±ç§‘æŠ€ç·¨è¼¯ã€‚ç‚ºä»¥ä¸‹æ–‡ç« å»ºç«‹è©³ç´°ç¶±è¦ï¼Œå¹«åŠ©è®€è€…å¿«é€Ÿäº†è§£ä»Šæ—¥é‡é»ã€‚

è¦æ±‚ï¼š
1. æ¯ç¯‡æ–‡ç« å¯« 2-3 å¥èªªæ˜æ ¸å¿ƒè§€é»åŠç‚ºä½•é‡è¦
2. å¦‚æœ‰é—œè¯ï¼ŒæŒ‡å‡ºæ–‡ç« ä¹‹é–“çš„é€£çµ
3. ä½¿ç”¨è‹±æ–‡
4. ç¸½é•·åº¦ï¼š800-1000 å­—

ç›´æ¥è¼¸å‡ºç¶±è¦ï¼Œä¸è¦åŠ å‰ç¶´ã€‚""",
            ),
            ("human", "æ–‡ç« ï¼š\n{articles}"),
        ]
    )

    # Format prompt
    format_prompt = ChatPromptTemplate.from_messages(
        [
            (
                "system",
                """ä½ æ˜¯ä¸€ä½ Telegram æ¨é€ç·¨è¼¯ã€‚å°‡ä»¥ä¸‹ç¶±è¦æ•´ç†æˆé©åˆ Telegram æ¨é€çš„æ ¼å¼ã€‚

è¦æ±‚ï¼š
1. æ¯ç¯‡æ–‡ç« å¯« 150-250 å­—çš„æ‘˜è¦
2. åŒ…å«ï¼šæ ¸å¿ƒè§€é»ã€é—œéµç™¼ç¾ã€ç‚ºä»€éº¼å€¼å¾—é—œæ³¨
3. å¯ç”¨ â€¢ æ¢åˆ—é‡é»
4. èªæ°£å°ˆæ¥­ä½†æ˜“è®€
5. **å¿…é ˆä½¿ç”¨ç¹é«”ä¸­æ–‡**ï¼ˆä¸å¯ä½¿ç”¨ç°¡é«”ä¸­æ–‡æˆ–è‹±æ–‡ï¼Œæ‰€æœ‰å…§å®¹éƒ½è¦ç¿»è­¯æˆç¹é«”ä¸­æ–‡ï¼‰

è¼¸å‡ºæ ¼å¼ï¼ˆæ¯ç¯‡æ–‡ç« ï¼‰ï¼š
æ¨™é¡Œ
æ‘˜è¦å…§å®¹ï¼ˆ150-250å­—ï¼‰
---

ç›´æ¥è¼¸å‡ºï¼Œä¸è¦é¡å¤–èªªæ˜ã€‚""",
            ),
            (
                "human",
                "åŸå§‹ç¶±è¦ï¼š\n{outline}\n\næ–‡ç« è³‡è¨Šï¼š\n{articles}",
            ),
        ]
    )

    # Node: Score items
    def score_items(state: IntelFeedState) -> dict[str, Any]:
        """è©•åˆ†æ‰€æœ‰é …ç›®"""
        items = state["items"]
        scored: list[ScoredItem] = []

        print(f"  [score] è©•åˆ† {len(items)} å€‹é …ç›®...", file=sys.stderr)

        for item in items:
            try:
                prompt = score_prompt.format(
                    title=item["title"],
                    source=item["sourceName"],
                    category=item["category"],
                )
                response = lite_llm.invoke(prompt)
                score_text = str(response.content).strip()
                score = min(10, max(1, int(score_text) if score_text.isdigit() else 5))
            except Exception as e:
                print(f"  [score] è©•åˆ†å¤±æ•—: {e}", file=sys.stderr)
                score = 5

            scored_item: ScoredItem = {**item, "relevanceScore": score}  # type: ignore[typeddict-item]
            scored.append(scored_item)

        avg_score = sum(i["relevanceScore"] for i in scored) / len(scored)
        print(f"  [score] å®Œæˆï¼Œå¹³å‡åˆ†æ•¸: {avg_score:.1f}", file=sys.stderr)
        return {"scored_items": scored}

    # Node: Filter and group items
    def filter_items(state: IntelFeedState) -> dict[str, Any]:
        """éæ¿¾ä½åˆ†é …ç›®ä¸¦æŒ‰é¡åˆ¥åˆ†çµ„"""
        scored = state["scored_items"]

        # éæ¿¾ä½åˆ†å’Œç„¡æ‘˜è¦çš„é …ç›®
        filtered = [
            item
            for item in scored
            if item["relevanceScore"] >= MIN_RELEVANCE_SCORE
            and item.get("summary")
            and item["summary"].strip()
            and item["summary"].strip() != "ç„¡æ‘˜è¦"
        ]

        print(f"  [filter] éæ¿¾å¾Œ: {len(filtered)}/{len(scored)} é …ç›®", file=sys.stderr)

        # æŒ‰é¡åˆ¥åˆ†çµ„
        by_category: dict[str, list[ScoredItem]] = {}
        for item in filtered:
            cat = item["category"]
            if cat not in by_category:
                by_category[cat] = []
            by_category[cat].append(item)

        # æ¯å€‹é¡åˆ¥å– top N
        for cat in by_category:
            by_category[cat] = sorted(
                by_category[cat], key=lambda x: x["relevanceScore"], reverse=True
            )[:ITEMS_PER_CATEGORY]

        categories = list(by_category.keys())
        print(f"  [filter] é¡åˆ¥: {categories}", file=sys.stderr)

        return {
            "filtered_items": by_category,
            "categories_to_process": categories,
        }

    # Node: Generate outlines for all categories
    def generate_outlines(state: IntelFeedState) -> dict[str, Any]:
        """ç‚ºæ¯å€‹é¡åˆ¥ç”Ÿæˆç¶±è¦"""
        filtered_items = state["filtered_items"]
        outlines: dict[str, str] = {}

        for category, items in filtered_items.items():
            if not items:
                continue

            print(f"  [outline] è™•ç† {category} ({len(items)} é …)...", file=sys.stderr)

            articles_text = "\n\n".join(
                f"{i + 1}. ã€{item['sourceName']}ã€‘{item['title']}\n"
                f"   {item.get('summary', 'ç„¡æ‘˜è¦')}\n"
                f"   é€£çµï¼š{item['url']}"
                for i, item in enumerate(items)
            )

            try:
                response = main_llm.invoke(outline_prompt.format(articles=articles_text))
                outlines[category] = str(response.content).strip()
            except Exception as e:
                print(f"  [outline] ç”Ÿæˆå¤±æ•—: {e}", file=sys.stderr)
                outlines[category] = "\n".join(
                    f"{item['title']}: {item.get('summary', 'ç„¡æ‘˜è¦')}" for item in items
                )

        return {"outlines": outlines}

    # Node: Format digests
    def format_digests(state: IntelFeedState) -> dict[str, Any]:
        """æ ¼å¼åŒ–ç‚ºæœ€çµ‚é€šçŸ¥"""
        filtered_items = state["filtered_items"]
        outlines = state["outlines"]
        digests: list[CategoryDigest] = []

        for category, items in filtered_items.items():
            if not items:
                continue

            outline = outlines.get(category, "")
            meta = CATEGORY_META.get(category, {"label": category, "emoji": "ğŸ“°"})

            print(f"  [format] æ ¼å¼åŒ– {category}...", file=sys.stderr)

            articles_text = "\n\n".join(
                f"{i + 1}. {item['title']}\n   ä¾†æºï¼š{item['sourceName']}\n   é€£çµï¼š{item['url']}"
                for i, item in enumerate(items)
            )

            try:
                response = main_llm.invoke(
                    format_prompt.format(outline=outline, articles=articles_text)
                )
                formatted = str(response.content).strip()

                # Parse formatted response
                digest_items = _parse_formatted_response(formatted, items)
            except Exception as e:
                print(f"  [format] æ ¼å¼åŒ–å¤±æ•—: {e}", file=sys.stderr)
                digest_items = [
                    DigestItem(
                        title=item["title"],
                        summary=item.get("summary") or "ç„¡æ‘˜è¦",
                        url=item["url"],
                        source=item["sourceName"],
                    )
                    for item in items
                ]

            digests.append(
                CategoryDigest(
                    category=category,
                    label=meta["label"],
                    emoji=meta["emoji"],
                    items=digest_items,
                )
            )

        return {"digests": digests}

    # Helper: Parse formatted response
    def _parse_formatted_response(response: str, items: list[ScoredItem]) -> list[DigestItem]:
        """è§£ææ ¼å¼åŒ–çš„å›æ‡‰"""
        blocks = [b.strip() for b in response.split("---") if b.strip()]
        digest_items: list[DigestItem] = []

        for i, item in enumerate(items):
            if i < len(blocks):
                lines = [line for line in blocks[i].split("\n") if line.strip()]
                summary = (
                    "\n".join(lines[1:]).strip()
                    if len(lines) > 1
                    else item.get("summary") or "ç„¡æ‘˜è¦"
                )
            else:
                summary = item.get("summary") or "ç„¡æ‘˜è¦"

            digest_items.append(
                DigestItem(
                    title=item["title"],
                    summary=summary,
                    url=item["url"],
                    source=item["sourceName"],
                )
            )

        return digest_items

    # Build graph
    workflow: StateGraph[IntelFeedState] = StateGraph(IntelFeedState)

    # Add nodes
    workflow.add_node("score", score_items)
    workflow.add_node("filter", filter_items)
    workflow.add_node("outline", generate_outlines)
    workflow.add_node("format", format_digests)

    # Add edges
    workflow.add_edge(START, "score")
    workflow.add_edge("score", "filter")

    # Conditional: skip if no items
    def should_continue(state: IntelFeedState) -> Literal["outline", "end"]:
        if not state.get("categories_to_process"):
            return "end"
        return "outline"

    workflow.add_conditional_edges(
        "filter",
        should_continue,
        {"outline": "outline", "end": END},
    )

    workflow.add_edge("outline", "format")
    workflow.add_edge("format", END)

    return workflow.compile()  # type: ignore[return-value]


def process_items(items: list[FeedItem]) -> list[CategoryDigest]:
    """è™•ç†æ–°èé …ç›®ä¸¦è¿”å›æ‘˜è¦"""
    if not items:
        return []

    graph = create_intel_feed_graph()

    initial_state: IntelFeedState = {
        "items": items,
        "scored_items": [],
        "filtered_items": {},
        "outlines": {},
        "digests": [],
        "categories_to_process": [],
    }

    print(f"[intel-feed-agent] é–‹å§‹è™•ç† {len(items)} å€‹é …ç›®", file=sys.stderr)
    result = graph.invoke(initial_state)
    print(f"[intel-feed-agent] å®Œæˆï¼Œç”Ÿæˆ {len(result['digests'])} å€‹é¡åˆ¥æ‘˜è¦", file=sys.stderr)

    return result["digests"]


def main() -> None:
    """ä¸»å…¥å£"""
    if len(sys.argv) < 2:
        print(json.dumps({"error": "Usage: agent.py <items_json>"}))
        sys.exit(1)

    try:
        items_json = sys.argv[1]
        items: list[FeedItem] = json.loads(items_json)

        digests = process_items(items)

        # Output JSON result
        print(json.dumps({"digests": digests}, ensure_ascii=False))

    except json.JSONDecodeError as e:
        print(json.dumps({"error": f"Invalid JSON: {e}"}))
        sys.exit(1)
    except Exception as e:
        print(json.dumps({"error": str(e)}))
        sys.exit(1)


if __name__ == "__main__":
    main()
