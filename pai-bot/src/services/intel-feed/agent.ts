/**
 * Intel Feed AI Agent
 * Uses Gemini with two-stage processing (lite â†’ flash)
 * Inspired by agentic_rag.py pattern
 */

import { GoogleGenAI } from "@google/genai";
import { logger } from "../../utils/logger";
import { CATEGORY_META, ITEMS_PER_CATEGORY, MIN_RELEVANCE_SCORE } from "./config";
import type { Category, CategoryDigest, DigestItem, FeedItem, ScoredItem } from "./types";

// Models
const LITE_MODEL = "gemini-2.5-flash-lite"; // Simple tasks: scoring, outline
const MAIN_MODEL = "gemini-2.5-flash"; // Complex tasks: final formatting

// Prompts
const SCORE_PROMPT = `You are a content scoring assistant. Rate the relevance of this article for a developer interested in AI/tech, startups, productivity tools, and TRPG.

Scoring criteria (1-10):
- 1-3: Irrelevant or low quality (ads, duplicates, no substance)
- 4-5: Generic content, no special value
- 6-7: Interesting, original, or valuable content worth knowing
- 8-10: High value content, must read

Reply with only a number (1-10), nothing else.

Title: {title}
Source: {source}
Category: {category}`;

const OUTLINE_PROMPT = `You are a senior tech editor. Create a detailed outline for the following articles to help readers quickly understand today's highlights.

Requirements:
1. Write 2-3 sentences per article explaining the core idea and why it matters
2. Point out connections between articles if any
3. Use English
4. Total length: 800-1000 words

Articles:
{articles}

Output the outline directly, no prefix.`;

const FORMAT_PROMPT = `ä½ æ˜¯ä¸€ä½ Telegram æ¨é€ç·¨è¼¯ã€‚è«‹å°‡ä»¥ä¸‹ç¶±è¦æ•´ç†æˆé©åˆ Telegram æ¨é€çš„æ ¼å¼ã€‚

è¦æ±‚ï¼š
1. æ¯ç¯‡æ–‡ç« å¯« 150-250 å­—çš„æ‘˜è¦
2. åŒ…å«ï¼šæ ¸å¿ƒè§€é»ã€é—œéµç™¼ç¾ã€ç‚ºä»€éº¼å€¼å¾—é—œæ³¨
3. å¯ç”¨ â€¢ æ¢åˆ—é‡é»
4. èªæ°£å°ˆæ¥­ä½†æ˜“è®€
5. **å¿…é ˆä½¿ç”¨ç¹é«”ä¸­æ–‡**ï¼ˆä¸å¯ä½¿ç”¨ç°¡é«”ä¸­æ–‡æˆ–è‹±æ–‡ï¼Œæ‰€æœ‰å…§å®¹éƒ½è¦ç¿»è­¯æˆç¹é«”ä¸­æ–‡ï¼‰

åŸå§‹ç¶±è¦ï¼š
{outline}

æ–‡ç« è³‡è¨Šï¼ˆç”¨æ–¼æ ¼å¼åŒ–ï¼‰ï¼š
{articles}

è¼¸å‡ºæ ¼å¼ï¼ˆæ¯ç¯‡æ–‡ç« ï¼‰ï¼š
æ¨™é¡Œ
æ‘˜è¦å…§å®¹ï¼ˆ150-250å­—ï¼‰
---

è«‹ç›´æ¥è¼¸å‡ºï¼Œä¸è¦é¡å¤–èªªæ˜ã€‚`;

export class IntelFeedAgent {
  private ai: GoogleGenAI;

  constructor() {
    const apiKey = process.env.GEMINI_API_KEY || process.env.GOOGLE_API_KEY;
    if (!apiKey) {
      throw new Error("GEMINI_API_KEY or GOOGLE_API_KEY is not set");
    }
    this.ai = new GoogleGenAI({ apiKey });
  }

  /**
   * Round 1: Score items by relevance (uses lite model)
   */
  async scoreItems(items: FeedItem[]): Promise<ScoredItem[]> {
    const scored: ScoredItem[] = [];

    // Process in batches to avoid rate limits
    const batchSize = 10;
    for (let i = 0; i < items.length; i += batchSize) {
      const batch = items.slice(i, i + batchSize);
      const batchResults = await Promise.all(batch.map((item) => this.scoreItem(item)));
      scored.push(...batchResults);

      // Small delay between batches
      if (i + batchSize < items.length) {
        await new Promise((resolve) => setTimeout(resolve, 500));
      }
    }

    return scored;
  }

  private async scoreItem(item: FeedItem): Promise<ScoredItem> {
    try {
      const prompt = SCORE_PROMPT.replace("{title}", item.title)
        .replace("{source}", item.sourceName)
        .replace("{category}", item.category);

      const response = await this.ai.models.generateContent({
        model: LITE_MODEL,
        contents: prompt,
        config: { maxOutputTokens: 10 },
      });

      const scoreText = response.text?.trim() || "5";
      const score = Math.min(10, Math.max(1, Number.parseInt(scoreText, 10) || 5));

      return { ...item, relevanceScore: score };
    } catch (error) {
      logger.warn({ error, title: item.title }, "Failed to score item");
      return { ...item, relevanceScore: 5 };
    }
  }

  /**
   * Round 2: Generate digests with two-stage processing
   * Stage 1 (lite): Create detailed outline (~1000 chars)
   * Stage 2 (flash): Refine into notification format
   */
  async generateDigests(items: ScoredItem[]): Promise<CategoryDigest[]> {
    // Filter by minimum score
    const filtered = items.filter((item) => item.relevanceScore >= MIN_RELEVANCE_SCORE);

    // Group by category
    const byCategory = new Map<Category, ScoredItem[]>();
    for (const item of filtered) {
      const existing = byCategory.get(item.category) || [];
      existing.push(item);
      byCategory.set(item.category, existing);
    }

    const digests: CategoryDigest[] = [];

    for (const [category, categoryItems] of byCategory) {
      // Sort by score, take top N
      const topItems = categoryItems
        .sort((a, b) => b.relevanceScore - a.relevanceScore)
        .slice(0, ITEMS_PER_CATEGORY);

      if (topItems.length === 0) continue;

      logger.info({ category, count: topItems.length }, "Processing category");

      // Stage 1: Generate outline with lite model
      const outline = await this.generateOutline(topItems);

      // Stage 2: Format with main model
      const digestItems = await this.formatDigest(topItems, outline);

      const meta = CATEGORY_META[category];
      digests.push({
        category,
        label: meta.label,
        emoji: meta.emoji,
        items: digestItems,
      });
    }

    return digests;
  }

  /**
   * Stage 1: Generate detailed outline (lite model)
   */
  private async generateOutline(items: ScoredItem[]): Promise<string> {
    try {
      const articlesText = items
        .map(
          (item, i) =>
            `${i + 1}. ã€${item.sourceName}ã€‘${item.title}\n   ${item.summary || "ç„¡æ‘˜è¦"}\n   é€£çµï¼š${item.url}`,
        )
        .join("\n\n");

      const prompt = OUTLINE_PROMPT.replace("{articles}", articlesText);

      const response = await this.ai.models.generateContent({
        model: MAIN_MODEL,
        contents: prompt,
        config: { maxOutputTokens: 2000 },
      });

      const outline = response.text?.trim() || "";
      logger.info({ length: outline.length }, "Generated outline with flash");
      return outline;
    } catch (error) {
      logger.error({ error }, "Failed to generate outline");
      // Fallback: return basic info
      return items.map((item) => `${item.title}: ${item.summary || "ç„¡æ‘˜è¦"}`).join("\n");
    }
  }

  /**
   * Stage 2: Format into notification (main model)
   */
  private async formatDigest(items: ScoredItem[], outline: string): Promise<DigestItem[]> {
    try {
      const articlesText = items
        .map(
          (item, i) => `${i + 1}. ${item.title}\n   ä¾†æºï¼š${item.sourceName}\n   é€£çµï¼š${item.url}`,
        )
        .join("\n\n");

      const prompt = FORMAT_PROMPT.replace("{outline}", outline).replace(
        "{articles}",
        articlesText,
      );

      const response = await this.ai.models.generateContent({
        model: MAIN_MODEL,
        contents: prompt,
        config: { maxOutputTokens: 4000 },
      });

      const formatted = response.text?.trim() || "";

      // Parse response into DigestItems
      return this.parseFormattedResponse(formatted, items);
    } catch (error) {
      logger.error({ error }, "Failed to format digest");
      // Fallback: use outline directly
      return items.map((item) => ({
        title: item.title,
        summary: item.summary || "ç„¡æ‘˜è¦",
        url: item.url,
        source: item.sourceName,
      }));
    }
  }

  /**
   * Parse formatted response into DigestItems
   */
  private parseFormattedResponse(response: string, items: ScoredItem[]): DigestItem[] {
    const blocks = response.split("---").filter((b) => b.trim());
    const digestItems: DigestItem[] = [];

    for (let i = 0; i < items.length; i++) {
      const item = items[i];
      const block = blocks[i]?.trim();

      if (block) {
        // Extract summary from block (skip first line which is title)
        const lines = block.split("\n").filter((l) => l.trim());
        const summary = lines.slice(1).join("\n").trim() || item.summary || "ç„¡æ‘˜è¦";

        digestItems.push({
          title: item.title,
          summary,
          url: item.url,
          source: item.sourceName,
        });
      } else {
        // Fallback if parsing fails
        digestItems.push({
          title: item.title,
          summary: item.summary || "ç„¡æ‘˜è¦",
          url: item.url,
          source: item.sourceName,
        });
      }
    }

    return digestItems;
  }

  /**
   * Format digests as notification messages
   * Returns: category overview + individual article notifications
   */
  formatNotifications(digests: CategoryDigest[]): Map<Category, string[]> {
    const notifications = new Map<Category, string[]>();

    for (const digest of digests) {
      const messages: string[] = [];

      // 1. Category overview (titles + links)
      const overviewLines: string[] = [
        `${digest.emoji} ${digest.label}ï¼ˆ${digest.items.length} å‰‡ç²¾é¸ï¼‰`,
        "",
      ];
      for (let i = 0; i < digest.items.length; i++) {
        const item = digest.items[i];
        overviewLines.push(`${i + 1}. ${item.title}`);
        overviewLines.push(`   ${item.url}`);
      }
      messages.push(overviewLines.join("\n"));

      // 2. Individual article notifications
      for (let i = 0; i < digest.items.length; i++) {
        const item = digest.items[i];
        const articleLines: string[] = [`ğŸ“° ${item.title}`, "", item.summary, "", `ğŸ”— ${item.url}`];
        messages.push(articleLines.join("\n"));
      }

      notifications.set(digest.category, messages);
    }

    return notifications;
  }
}
